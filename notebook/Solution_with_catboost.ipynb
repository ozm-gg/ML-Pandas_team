{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faedd892-f2b3-4eb5-a9b3-eefad26e5df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_percentage_error, \n",
    "    mean_squared_log_error, \n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "\n",
    "def calc_all_metrics(data: Any) -> Dict[str, float]:\n",
    "    def is_credit_issued(x: Any):\n",
    "        ratio = x['__price_predict'] / x['__price_doc']\n",
    "        if x['__priority'] <= 0:\n",
    "            value = 0.0\n",
    "        elif 0.9 < ratio < 1.0:\n",
    "            value = x['__price_predict']\n",
    "        elif 1.0 <= ratio < 1.1:\n",
    "            value = x['__price_doc']\n",
    "        else:\n",
    "            value = 0.0\n",
    "\n",
    "        return value\n",
    "\n",
    "    def calc_profit(x: pd.DataFrame) -> np.array:\n",
    "        if x['is_credit'] == 0.0:\n",
    "            return 0.0\n",
    "        if x['__churn'] == 1:\n",
    "            return -x['debt'] * 2.0\n",
    "        if x['debt'] < 5:\n",
    "            return x['debt'] * 0.3\n",
    "        if x['debt'] < 9:\n",
    "            return x['debt'] * 0.4\n",
    "        if x['debt'] >= 9:\n",
    "            return x['debt'] * 0.5\n",
    "\n",
    "    max_account = 25e3\n",
    "    \n",
    "    s = (\n",
    "        data[['__priority', '__churn', '__churn_prob', '__price_doc', '__price_predict']]\n",
    "        .sort_values('__priority', ascending=False)\n",
    "        .copy(True)\n",
    "    )\n",
    "\n",
    "    s['debt'] = s.apply(is_credit_issued, axis=1)\n",
    "    s['debt_cum'] = s['debt'].cumsum()\n",
    "    s['is_credit'] = 0\n",
    "    s.loc[(s['debt'] > 0) & (s['debt_cum'] <= max_account), 'is_credit'] = 1\n",
    "    s['profit'] = s.apply(calc_profit, axis=1)\n",
    "\n",
    "    total_profit = round(s['profit'].sum(), 2)\n",
    "    good_credits_count = int(s['is_credit'].sum())\n",
    "    good_credits_debt = int(s[s['is_credit'] == 1]['debt'].sum())\n",
    "    bad_credits_count = s[s['is_credit'] == 1]['__churn'].sum()\n",
    "\n",
    "    return {\n",
    "        'total_profit': int(total_profit),\n",
    "        'issue_amount': good_credits_debt,\n",
    "        'bad_loans': round(bad_credits_count / (good_credits_count + bad_credits_count) * 100.0, 1),\n",
    "        'churn_auc': round(roc_auc_score(y_true=s['__churn'], y_score=s['__churn_prob']), 3),\n",
    "        'price_nmsle': round(\n",
    "            -mean_squared_log_error(y_true=s['__price_doc'], y_pred=s['__price_predict']),\n",
    "            3,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "METRICS_DESC = {\n",
    "    'total_profit': 'Итоговая полученная прибыль (Ключевая метрика), млн руб.',\n",
    "    'issue_amount': 'Итоговая выданная сумма (25 000 максимум), млн руб.',\n",
    "    'bad_loans': 'Доля выданных кредитов с задолженностью, %',\n",
    "    'churn_auc': 'Метрика ROC AUC по модели предсказания задолженности',\n",
    "    'price_nmsle': 'Метрика Negative Mean Squared Logarithmic Error по модели предсказания стоимости',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d5c6fa-45bc-4174-a820-a124360f0765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/submissions/ml_pandas_2024-12-01_1317.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d_%H%M')\n",
    "SUBMISSION_PATH = f'../data/submissions/ml_pandas_{now}.csv'\n",
    "SUBMISSION_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe70066-79ba-4b2c-b506-ba8136c5a8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20483, 61), (9988, 59))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "submission = pd.read_csv('../data/test.csv')\n",
    "data.shape, submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5600157b-c444-4f68-8363-4608b8fa62e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20483 entries, 0 to 20482\n",
      "Data columns (total 14 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   max_floor                    10911 non-null  float64\n",
      " 1   state                        8469 non-null   float64\n",
      " 2   railroad_station_walk_km     20473 non-null  float64\n",
      " 3   0_17_all                     18080 non-null  float64\n",
      " 4   build_count_wood             17420 non-null  float64\n",
      " 5   life_sq                      16290 non-null  float64\n",
      " 6   cafe_sum_1000_min_price_avg  15887 non-null  float64\n",
      " 7   metro_km_walk                20473 non-null  float64\n",
      " 8   total_trans_amt              18080 non-null  float64\n",
      " 9   cafe_sum_1500_min_price_avg  17485 non-null  float64\n",
      " 10  floor                        20316 non-null  float64\n",
      " 11  num_room                     10911 non-null  float64\n",
      " 12  build_year                   8901 non-null   float64\n",
      " 13  build_count_mix              17420 non-null  float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "data.loc[:, data.isnull().any()].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65fbc226-343b-45a5-9f91-8c7779d1ea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20483 entries, 0 to 20482\n",
      "Data columns (total 61 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   max_floor                              10911 non-null  float64\n",
      " 1   state                                  8469 non-null   float64\n",
      " 2   marital_status                         20483 non-null  object \n",
      " 3   big_market_raion                       20483 non-null  object \n",
      " 4   total_revolving_bal                    20483 non-null  int64  \n",
      " 5   market_count_1500                      20483 non-null  int64  \n",
      " 6   leisure_count_3000                     20483 non-null  int64  \n",
      " 7   total_ct_chng_q4_q1                    20483 non-null  float64\n",
      " 8   water_1line                            20483 non-null  object \n",
      " 9   railroad_station_walk_km               20473 non-null  float64\n",
      " 10  culture_objects_top_25                 20483 non-null  object \n",
      " 11  contacts_count_12_mon                  20483 non-null  int64  \n",
      " 12  0_17_all                               18080 non-null  float64\n",
      " 13  trc_count_2000                         20483 non-null  int64  \n",
      " 14  product_type                           20483 non-null  object \n",
      " 15  build_count_wood                       17420 non-null  float64\n",
      " 16  credit_limit                           20483 non-null  float64\n",
      " 17  total_trans_ct                         20483 non-null  int64  \n",
      " 18  leisure_count_5000                     20483 non-null  int64  \n",
      " 19  life_sq                                16290 non-null  float64\n",
      " 20  cafe_count_1000_price_1000             20483 non-null  int64  \n",
      " 21  mkad_km                                20483 non-null  float64\n",
      " 22  school_education_centers_top_20_raion  20483 non-null  int64  \n",
      " 23  big_road1_1line                        20483 non-null  object \n",
      " 24  card_category                          20483 non-null  object \n",
      " 25  avg_utilization_ratio                  20483 non-null  float64\n",
      " 26  public_transport_station_min_walk      20483 non-null  float64\n",
      " 27  income_category                        20483 non-null  object \n",
      " 28  customer_age                           20483 non-null  int64  \n",
      " 29  thermal_power_plant_raion              20483 non-null  object \n",
      " 30  radiation_raion                        20483 non-null  object \n",
      " 31  detention_facility_km                  20483 non-null  float64\n",
      " 32  sport_count_2000                       20483 non-null  int64  \n",
      " 33  cafe_sum_1000_min_price_avg            15887 non-null  float64\n",
      " 34  total_amt_chng_q4_q1                   20483 non-null  float64\n",
      " 35  ecology                                20483 non-null  object \n",
      " 36  metro_km_walk                          20473 non-null  float64\n",
      " 37  office_sqm_5000                        20483 non-null  int64  \n",
      " 38  gender                                 20483 non-null  object \n",
      " 39  oil_chemistry_raion                    20483 non-null  object \n",
      " 40  nuclear_reactor_raion                  20483 non-null  object \n",
      " 41  total_trans_amt                        18080 non-null  float64\n",
      " 42  months_inactive_12_mon                 20483 non-null  int64  \n",
      " 43  cafe_sum_1500_min_price_avg            17485 non-null  float64\n",
      " 44  railroad_1line                         20483 non-null  object \n",
      " 45  floor                                  20316 non-null  float64\n",
      " 46  num_room                               10911 non-null  float64\n",
      " 47  timestamp                              20483 non-null  object \n",
      " 48  education_level                        20483 non-null  object \n",
      " 49  months_on_book                         20483 non-null  int64  \n",
      " 50  dependent_count                        20483 non-null  int64  \n",
      " 51  avg_open_to_buy                        20483 non-null  float64\n",
      " 52  build_year                             8901 non-null   float64\n",
      " 53  incineration_raion                     20483 non-null  object \n",
      " 54  full_sq                                20483 non-null  int64  \n",
      " 55  total_relationship_count               20483 non-null  int64  \n",
      " 56  detention_facility_raion               20483 non-null  object \n",
      " 57  build_count_mix                        17420 non-null  float64\n",
      " 58  railroad_terminal_raion                20483 non-null  object \n",
      " 59  __churn                                20483 non-null  int64  \n",
      " 60  __price_doc                            20483 non-null  float64\n",
      "dtypes: float64(23), int64(18), object(20)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc479a7-96d8-420a-acab-b84cb0b999cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Выделяем метки и удаляем их из данных\n",
    "churn = data[\"__churn\"]\n",
    "price = data[\"__price_doc\"]\n",
    "data = data.drop([\"__churn\", \"__price_doc\"], axis=1)\n",
    "\n",
    "data = data.drop([\"timestamp\"], axis=1)\n",
    "submission = submission.drop([\"timestamp\"], axis=1)\n",
    "\n",
    "# Удаляем столбцы с большим количеством пропусков\n",
    "threshold = 0.4\n",
    "missing_fraction = data.isnull().mean()\n",
    "columns_to_drop = missing_fraction[missing_fraction > threshold].index\n",
    "\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "submission = submission.drop(columns=columns_to_drop)\n",
    "\n",
    "# Разделяем столбцы на числовые и категориальные\n",
    "numeric_cols = data.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "categorical_cols = data.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Заполняем числовые данные медианой\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "data[numeric_cols] = num_imputer.fit_transform(data[numeric_cols])\n",
    "submission[numeric_cols] = num_imputer.transform(submission[numeric_cols])\n",
    "\n",
    "# Заполняем категориальные данные самым частым значением\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "data[categorical_cols] = cat_imputer.fit_transform(data[categorical_cols])\n",
    "submission[categorical_cols] = cat_imputer.transform(submission[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a62048-3f2d-4823-bdcf-12b2ae45a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "price_scaler = StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "submission[numeric_cols] = scaler.transform(submission[numeric_cols])\n",
    "\n",
    "price_scaled = price_scaler.fit_transform(price.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a3c6ad-9e23-423f-96d0-3d2360a08f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20483 entries, 0 to 20482\n",
      "Data columns (total 54 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   marital_status                         20483 non-null  object \n",
      " 1   big_market_raion                       20483 non-null  object \n",
      " 2   total_revolving_bal                    20483 non-null  float64\n",
      " 3   market_count_1500                      20483 non-null  float64\n",
      " 4   leisure_count_3000                     20483 non-null  float64\n",
      " 5   total_ct_chng_q4_q1                    20483 non-null  float64\n",
      " 6   water_1line                            20483 non-null  object \n",
      " 7   railroad_station_walk_km               20483 non-null  float64\n",
      " 8   culture_objects_top_25                 20483 non-null  object \n",
      " 9   contacts_count_12_mon                  20483 non-null  float64\n",
      " 10  0_17_all                               20483 non-null  float64\n",
      " 11  trc_count_2000                         20483 non-null  float64\n",
      " 12  product_type                           20483 non-null  object \n",
      " 13  build_count_wood                       20483 non-null  float64\n",
      " 14  credit_limit                           20483 non-null  float64\n",
      " 15  total_trans_ct                         20483 non-null  float64\n",
      " 16  leisure_count_5000                     20483 non-null  float64\n",
      " 17  life_sq                                20483 non-null  float64\n",
      " 18  cafe_count_1000_price_1000             20483 non-null  float64\n",
      " 19  mkad_km                                20483 non-null  float64\n",
      " 20  school_education_centers_top_20_raion  20483 non-null  float64\n",
      " 21  big_road1_1line                        20483 non-null  object \n",
      " 22  card_category                          20483 non-null  object \n",
      " 23  avg_utilization_ratio                  20483 non-null  float64\n",
      " 24  public_transport_station_min_walk      20483 non-null  float64\n",
      " 25  income_category                        20483 non-null  object \n",
      " 26  customer_age                           20483 non-null  float64\n",
      " 27  thermal_power_plant_raion              20483 non-null  object \n",
      " 28  radiation_raion                        20483 non-null  object \n",
      " 29  detention_facility_km                  20483 non-null  float64\n",
      " 30  sport_count_2000                       20483 non-null  float64\n",
      " 31  cafe_sum_1000_min_price_avg            20483 non-null  float64\n",
      " 32  total_amt_chng_q4_q1                   20483 non-null  float64\n",
      " 33  ecology                                20483 non-null  object \n",
      " 34  metro_km_walk                          20483 non-null  float64\n",
      " 35  office_sqm_5000                        20483 non-null  float64\n",
      " 36  gender                                 20483 non-null  object \n",
      " 37  oil_chemistry_raion                    20483 non-null  object \n",
      " 38  nuclear_reactor_raion                  20483 non-null  object \n",
      " 39  total_trans_amt                        20483 non-null  float64\n",
      " 40  months_inactive_12_mon                 20483 non-null  float64\n",
      " 41  cafe_sum_1500_min_price_avg            20483 non-null  float64\n",
      " 42  railroad_1line                         20483 non-null  object \n",
      " 43  floor                                  20483 non-null  float64\n",
      " 44  education_level                        20483 non-null  object \n",
      " 45  months_on_book                         20483 non-null  float64\n",
      " 46  dependent_count                        20483 non-null  float64\n",
      " 47  avg_open_to_buy                        20483 non-null  float64\n",
      " 48  incineration_raion                     20483 non-null  object \n",
      " 49  full_sq                                20483 non-null  float64\n",
      " 50  total_relationship_count               20483 non-null  float64\n",
      " 51  detention_facility_raion               20483 non-null  object \n",
      " 52  build_count_mix                        20483 non-null  float64\n",
      " 53  railroad_terminal_raion                20483 non-null  object \n",
      "dtypes: float64(35), object(19)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3323ed67-c5e0-4453-bbb6-f12157749838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmits\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:241: UserWarning: Found unknown categories in columns [15] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\", handle_unknown='ignore')\n",
    "encoded_data = pd.DataFrame(encoder.fit_transform(data[categorical_cols]), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "data = pd.concat([data.drop(categorical_cols, axis=1), encoded_data], axis=1)\n",
    "\n",
    "encoded_submission = pd.DataFrame(encoder.transform(submission[categorical_cols]), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "submission = pd.concat([submission.drop(categorical_cols, axis=1), encoded_submission], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5b583e-9652-4d66-a4ba-3a66f26b6835",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    data[col] = encoder.fit_transform(data[col])\n",
    "    submission[col] = encoder.transform(submission[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "000cc35a-ea28-4f4b-9118-0e4e1ed05868",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Single'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8881/2313253937.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchurn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfeature_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m feature_importance_df = pd.DataFrame({\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m'Feature'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         raise ValueError(\n\u001b[1;32m   1298\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         )\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1302\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                         )\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n\u001b[1;32m   1015\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Single'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(data, churn)\n",
    "feature_importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': data.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "important_features = np.array(data.columns)[feature_importances > 0.01]\n",
    "data = data[important_features]\n",
    "submission = submission[important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53ad2898-9dc4-43cb-82cc-29efa97bb081",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_importance_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature_importance_df \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_importance_df\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m feature_importance_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_importance_df' is not defined"
     ]
    }
   ],
   "source": [
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "feature_importance_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01be20df-4066-4299-89a4-b866875a3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "\n",
    "X_train, X_val, y_churn_train, y_churn_val, y_price_train, y_price_val = train_test_split(\n",
    "    data, churn, price_scaled, test_size=0.5, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aad3eff-becd-427c-8b8a-93186efba114",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Single'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11642/767588385.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mchurn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mchurn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_churn_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprice_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprice_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_price_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \"\"\"\n\u001b[1;32m    262\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         return self._partial_fit(\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_refit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_refit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_partial_fit_first_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         raise ValueError(\n\u001b[1;32m   1298\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         )\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1302\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                         )\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n\u001b[1;32m   1015\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Single'"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "churn_model = GaussianNB()\n",
    "churn_model.fit(X_train, y_churn_train)\n",
    "\n",
    "price_model = RandomForestRegressor(n_estimators = 1000, max_depth = 7)\n",
    "price_model.fit(X_train, y_price_train)\n",
    "\n",
    "y_price_pred = price_model.predict(X_val)\n",
    "y_churn_pred = churn_model.predict(X_val)\n",
    "y_price_pred_tr = price_model.predict(X_train)\n",
    "y_churn_pred_tr = churn_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7b3ef1-377e-47e4-b3e8-15d6fd3c9aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6752085\ttest: 0.6751386\tbest: 0.6751386 (0)\ttotal: 69.6ms\tremaining: 6m 57s\n",
      "200:\tlearn: 0.1675963\ttest: 0.1703534\tbest: 0.1703534 (200)\ttotal: 3.23s\tremaining: 1m 33s\n",
      "400:\tlearn: 0.1475558\ttest: 0.1571859\tbest: 0.1571859 (400)\ttotal: 6.89s\tremaining: 1m 36s\n",
      "600:\tlearn: 0.1371161\ttest: 0.1532760\tbest: 0.1532760 (600)\ttotal: 10.6s\tremaining: 1m 35s\n",
      "800:\tlearn: 0.1290214\ttest: 0.1513533\tbest: 0.1513515 (799)\ttotal: 14.1s\tremaining: 1m 31s\n",
      "1000:\tlearn: 0.1208860\ttest: 0.1496822\tbest: 0.1496822 (1000)\ttotal: 17.9s\tremaining: 1m 29s\n",
      "1200:\tlearn: 0.1136444\ttest: 0.1487112\tbest: 0.1487112 (1200)\ttotal: 21.4s\tremaining: 1m 25s\n",
      "1400:\tlearn: 0.1079533\ttest: 0.1481302\tbest: 0.1481302 (1400)\ttotal: 25.1s\tremaining: 1m 22s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1479692017\n",
      "bestIteration = 1456\n",
      "\n",
      "Shrink model to first 1457 iterations.\n",
      "ROC AUC Score for Churn Prediction: 0.9748\n",
      "0:\tlearn: 1.0015274\ttest: 0.9976608\tbest: 0.9976608 (0)\ttotal: 8.16ms\tremaining: 49s\n",
      "200:\tlearn: 0.9248784\ttest: 0.9191080\tbest: 0.9191080 (200)\ttotal: 1.74s\tremaining: 50.1s\n",
      "400:\tlearn: 0.8652104\ttest: 0.8585026\tbest: 0.8585026 (400)\ttotal: 3.45s\tremaining: 48.2s\n",
      "600:\tlearn: 0.8183638\ttest: 0.8113460\tbest: 0.8113460 (600)\ttotal: 5.16s\tremaining: 46.4s\n",
      "800:\tlearn: 0.7815088\ttest: 0.7752946\tbest: 0.7752946 (800)\ttotal: 6.88s\tremaining: 44.7s\n",
      "1000:\tlearn: 0.7524448\ttest: 0.7477003\tbest: 0.7477003 (1000)\ttotal: 8.57s\tremaining: 42.8s\n",
      "1200:\tlearn: 0.7290230\ttest: 0.7262578\tbest: 0.7262578 (1200)\ttotal: 10.3s\tremaining: 41s\n",
      "1400:\tlearn: 0.7099107\ttest: 0.7094676\tbest: 0.7094676 (1400)\ttotal: 12.1s\tremaining: 39.7s\n",
      "1600:\tlearn: 0.6941355\ttest: 0.6968295\tbest: 0.6968295 (1600)\ttotal: 13.8s\tremaining: 37.9s\n",
      "1800:\tlearn: 0.6809689\ttest: 0.6866515\tbest: 0.6866515 (1800)\ttotal: 15.5s\tremaining: 36.2s\n",
      "2000:\tlearn: 0.6698267\ttest: 0.6783828\tbest: 0.6783828 (2000)\ttotal: 17.3s\tremaining: 34.5s\n",
      "2200:\tlearn: 0.6601763\ttest: 0.6718972\tbest: 0.6718972 (2200)\ttotal: 19s\tremaining: 32.7s\n",
      "2400:\tlearn: 0.6517807\ttest: 0.6664952\tbest: 0.6664952 (2400)\ttotal: 20.7s\tremaining: 31s\n",
      "2600:\tlearn: 0.6443930\ttest: 0.6620019\tbest: 0.6620019 (2600)\ttotal: 22.4s\tremaining: 29.3s\n",
      "2800:\tlearn: 0.6378712\ttest: 0.6580743\tbest: 0.6580743 (2800)\ttotal: 24.1s\tremaining: 27.5s\n",
      "3000:\tlearn: 0.6319622\ttest: 0.6548486\tbest: 0.6548486 (3000)\ttotal: 25.7s\tremaining: 25.7s\n",
      "3200:\tlearn: 0.6266838\ttest: 0.6519279\tbest: 0.6519279 (3200)\ttotal: 27.4s\tremaining: 23.9s\n",
      "3400:\tlearn: 0.6218843\ttest: 0.6492746\tbest: 0.6492746 (3400)\ttotal: 29.1s\tremaining: 22.2s\n",
      "3600:\tlearn: 0.6173669\ttest: 0.6470517\tbest: 0.6470517 (3600)\ttotal: 30.9s\tremaining: 20.6s\n",
      "3800:\tlearn: 0.6134623\ttest: 0.6450830\tbest: 0.6450830 (3800)\ttotal: 33.2s\tremaining: 19.2s\n",
      "4000:\tlearn: 0.6099419\ttest: 0.6434951\tbest: 0.6434951 (4000)\ttotal: 35.1s\tremaining: 17.5s\n",
      "4200:\tlearn: 0.6066720\ttest: 0.6420996\tbest: 0.6420996 (4200)\ttotal: 37.3s\tremaining: 16s\n",
      "4400:\tlearn: 0.6036307\ttest: 0.6408183\tbest: 0.6408183 (4400)\ttotal: 39.2s\tremaining: 14.2s\n",
      "4600:\tlearn: 0.6008193\ttest: 0.6396546\tbest: 0.6396546 (4600)\ttotal: 41s\tremaining: 12.5s\n",
      "4800:\tlearn: 0.5981055\ttest: 0.6385951\tbest: 0.6385951 (4800)\ttotal: 42.7s\tremaining: 10.7s\n",
      "5000:\tlearn: 0.5955938\ttest: 0.6376431\tbest: 0.6376431 (5000)\ttotal: 44.4s\tremaining: 8.87s\n",
      "5200:\tlearn: 0.5931773\ttest: 0.6367257\tbest: 0.6367257 (5200)\ttotal: 46.2s\tremaining: 7.09s\n",
      "5400:\tlearn: 0.5908597\ttest: 0.6359140\tbest: 0.6359140 (5400)\ttotal: 47.9s\tremaining: 5.31s\n",
      "5600:\tlearn: 0.5887140\ttest: 0.6351565\tbest: 0.6351565 (5600)\ttotal: 49.5s\tremaining: 3.52s\n",
      "5800:\tlearn: 0.5865918\ttest: 0.6344636\tbest: 0.6344636 (5800)\ttotal: 51.1s\tremaining: 1.75s\n",
      "5999:\tlearn: 0.5845925\ttest: 0.6338151\tbest: 0.6338151 (5999)\ttotal: 52.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.633815078\n",
      "bestIteration = 5999\n",
      "\n",
      "RMSE for Price Prediction: 2.8701\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "\n",
    "cat_features = [i for i in X_train.columns if X_train[i].dtype == 'object']\n",
    "\n",
    "# Создание и обучение модели для классификации вероятности задолженности\n",
    "churn_model = CatBoostClassifier(\n",
    "    iterations= 6000,\n",
    "    learning_rate=0.01,\n",
    "    depth=6,\n",
    "    cat_features=cat_features,\n",
    "    verbose=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "churn_model.fit(X_train, y_churn_train, eval_set=(X_val, y_churn_val), early_stopping_rounds=50)\n",
    "\n",
    "y_churn_pred = churn_model.predict_proba(X_val)[:, 1]\n",
    "y_churn_pred_tr = churn_model.predict_proba(X_train)[:, 1]\n",
    "roc_auc = roc_auc_score(y_churn_val, y_churn_pred)\n",
    "print(f'ROC AUC Score for Churn Prediction: {roc_auc:.4f}')\n",
    "\n",
    "# Создание и обучение модели для предсказания цены квартиры\n",
    "price_model = CatBoostRegressor(\n",
    "    iterations=6000,\n",
    "    learning_rate=0.001,\n",
    "    depth=6,\n",
    "    cat_features=cat_features,\n",
    "    verbose=200,\n",
    "    random_state=42\n",
    ")\n",
    "price_model.fit(X_train, y_price_train, eval_set=(X_val, y_price_val), early_stopping_rounds=50)\n",
    "\n",
    "# Оценка производительности регрессии\n",
    "y_price_pred = price_model.predict(X_val)\n",
    "y_price_pred_tr = price_model.predict(X_train)\n",
    "rmse = np.sqrt(mean_squared_error(price_scaler.inverse_transform(y_price_val.reshape(-1, 1)), price_scaler.inverse_transform(y_price_pred.reshape(-1, 1))))\n",
    "print(f'RMSE for Price Prediction: {rmse:.4f}')\n",
    "\n",
    "# Предсказание на тестовом наборе\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bd7a456-d0ff-4b1e-8d63-a833c31e2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['__churn_prob'] = churn_model.predict_proba(submission)[:, 1]\n",
    "submission['__price_predict'] = price_scaler.inverse_transform(price_model.predict(submission.drop(['__churn_prob'], axis = 1)).reshape(-1, 1))\n",
    "submission.loc[submission['__price_predict'] < 0.01, '__price_predict'] = 0.01\n",
    "#submission.loc[submission['__churn_prob'] < 0.01, '__churn_prob'] = 0.01\n",
    "# Создание приоритета\n",
    "#submission['__priority'] = (submission['__churn_prob'] * submission['__price_predict']).rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a69e9c0-7529-4368-afdb-88d75b833ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "test['__churn'] = y_churn_val\n",
    "test['__price_doc'] = price_scaler.inverse_transform(y_price_val.reshape(-1, 1))\n",
    "test['__price_predict'] = price_scaler.inverse_transform(y_price_pred.reshape(-1, 1))\n",
    "test['__churn_prob'] = y_churn_pred\n",
    "test.loc[test['__price_predict'] < 0.01, '__price_predict'] = 0.01\n",
    "#test.loc[test['__churn_prob'] < 0.01, '__churn_prob'] = 0.01\n",
    "#test['__priority'] = (test['__churn_prob'] * test['__price_predict']).rank(ascending=False)\n",
    "\n",
    "\n",
    "train['__churn'] = y_churn_train\n",
    "train['__price_doc'] = price_scaler.inverse_transform(y_price_train.reshape(-1, 1))\n",
    "train['__price_predict'] = price_scaler.inverse_transform(y_price_pred_tr.reshape(-1, 1))\n",
    "train['__churn_prob'] = y_churn_pred_tr\n",
    "train.loc[train['__price_predict'] < 0.01, '__price_predict'] = 0.01\n",
    "#train.loc[train['__churn_prob'] < 0.01, '__churn_prob'] = 0.01\n",
    "#train['__priority'] = (train['__churn_prob'] * train['__price_predict']).rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d147727a-fdb6-472c-a4bd-c013879d1c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.0+cu124)\n",
      "Requirement already satisfied: torchvision in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.0+cu124)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.0+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dmits\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b29f0a11-a88c-4483-ac85-42dd5d516984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5d06a08-d8a7-489f-9c43-5bcfafd98066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(PriorityPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dbe265d-1f1b-4dc7-8a0d-33b824b6a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PriorityPredictor(2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "epochs = 50\n",
    "def apply_model(data):\n",
    "    data_tensor = torch.tensor(data[['__churn_prob', '__price_predict']].values, dtype=torch.float32)\n",
    "    return model(data_tensor)\n",
    "\n",
    "def pseudo_profit(priorities, data):\n",
    "    sorted_indices = np.argsort(-priorities.detach().numpy())\n",
    "    result = 0\n",
    "    for i, idx in enumerate(sorted_indices):\n",
    "        row = data.iloc[idx]\n",
    "        x = row['__price_predict']/ row['__price_doc']\n",
    "        result += (1 / ((i + 1) **0.1)) * torch.exp(-((torch.tensor(x.iloc[0])-1)/10)**10) * priorities[idx] \n",
    "        if i >= 25e3:\n",
    "            break;\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56d9dde4-cbef-40bf-ae5e-d3741b57578f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1173],\n",
       "        [0.1347],\n",
       "        [0.1379],\n",
       "        ...,\n",
       "        [0.1062],\n",
       "        [0.1255],\n",
       "        [0.1264]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_model(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fc21107-ec80-46e6-8796-bb1840d1f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = -pseudo_profit(apply_model(train), train)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd4e9c18-6b7a-425e-821b-d044b8686d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1730.3378],\n",
       "        [2059.5945],\n",
       "        [2119.8738],\n",
       "        ...,\n",
       "        [1403.0768],\n",
       "        [2217.1196],\n",
       "        [1904.1329]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_model(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367de100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg(x, min_treshholdm, price_scaler, price_importance):\n",
    "    return - (x['__price_predict'] ** price_importance) * np.log(min_treshholdm + (1 - min_treshholdm)* np.tanh((x['__price_predict']*price_scaler)) + x['__churn_prob'])\n",
    "\n",
    "train['__priority'] = train.apply(lambda x: alg(x , 0.7, 0.1, 0.1), axis=1)\n",
    "test['__priority'] = test.apply(lambda x: alg(x , 0.7, 0, 0.1), axis=1)\n",
    "submission['__priority'] = submission.apply(lambda x: alg(x , 0.7, 0, 0.1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6cdabb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:15<00:00,  1.71s/it]\n",
      "100%|██████████| 9/9 [00:12<00:00,  1.43s/it]]\n",
      "100%|██████████| 9/9 [00:12<00:00,  1.44s/it]]\n",
      "100%|██████████| 9/9 [00:14<00:00,  1.58s/it]]\n",
      "100%|██████████| 9/9 [00:14<00:00,  1.61s/it]]\n",
      "100%|██████████| 9/9 [00:14<00:00,  1.57s/it]]\n",
      "100%|██████████| 9/9 [00:14<00:00,  1.61s/it]]\n",
      "100%|██████████| 9/9 [00:14<00:00,  1.61s/it]]\n",
      "100%|██████████| 9/9 [00:14<00:00,  1.60s/it]]\n",
      "100%|██████████| 9/9 [00:14<00:00,  1.59s/it]]\n",
      "100%|██████████| 10/10 [02:21<00:00, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7264, 0.7000000000000001, 0.1, 0.1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "results = [0,0,0,0]\n",
    "for treshold_min in tqdm.tqdm(np.arange(0,1,0.1)):\n",
    "    for price_scal in tqdm.tqdm(np.arange(0.1, 1, 0.1)):\n",
    "        for price_importance in np.arange(0.1, 1, 0.2):\n",
    "            test['__priority'] = test.apply(lambda x: alg(x , treshold_min, price_scal, price_importance), axis=1)\n",
    "            tp = calc_all_metrics(test)[\"total_profit\"]\n",
    "            if results[0] < tp:\n",
    "                results = [tp, treshold_min, price_scal, price_importance]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b6d315-97b2-479f-bfb9-fcc3b76b10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def alg(x):\n",
    "#     return model(torch.tensor(x[['__churn_prob', '__price_predict']].values, dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "\n",
    "# train['__priority'] = train.apply(alg, axis=1)\n",
    "# test['__priority'] = test.apply(alg, axis=1)\n",
    "# submission['__priority'] = submission.apply(alg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "879949dc-0d4e-4bd3-b65a-9812c3d3c81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_profit</th>\n",
       "      <td>7475.000</td>\n",
       "      <td>7164.000</td>\n",
       "      <td>Итоговая полученная прибыль (Ключевая метрика)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue_amount</th>\n",
       "      <td>20469.000</td>\n",
       "      <td>20943.000</td>\n",
       "      <td>Итоговая выданная сумма (25 000 максимум), млн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad_loans</th>\n",
       "      <td>1.500</td>\n",
       "      <td>2.500</td>\n",
       "      <td>Доля выданных кредитов с задолженностью, %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn_auc</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.975</td>\n",
       "      <td>Метрика ROC AUC по модели предсказания задолже...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_nmsle</th>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>Метрика Negative Mean Squared Logarithmic Erro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train       test  \\\n",
       "total_profit   7475.000   7164.000   \n",
       "issue_amount  20469.000  20943.000   \n",
       "bad_loans         1.500      2.500   \n",
       "churn_auc         0.990      0.975   \n",
       "price_nmsle      -0.145     -0.142   \n",
       "\n",
       "                                                           desc  \n",
       "total_profit  Итоговая полученная прибыль (Ключевая метрика)...  \n",
       "issue_amount  Итоговая выданная сумма (25 000 максимум), млн...  \n",
       "bad_loans            Доля выданных кредитов с задолженностью, %  \n",
       "churn_auc     Метрика ROC AUC по модели предсказания задолже...  \n",
       "price_nmsle   Метрика Negative Mean Squared Logarithmic Erro...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pd.concat([\n",
    "    pd.Series(calc_all_metrics(train), name='train'),\n",
    "    pd.Series(calc_all_metrics(test), name='test'),\n",
    "], axis=1)\n",
    "\n",
    "# добавляем колонку с описанием метрики\n",
    "score['desc'] = score.index.map(METRICS_DESC)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8d9fc21-2795-452a-b72a-7977cf64b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysub = submission[['__price_predict', '__churn_prob', '__priority']]\n",
    "mysub.to_csv(SUBMISSION_PATH, index=False)\n",
    "\n",
    "if mysub.shape != (9988, 3):\n",
    "    raise ValueError('Неправильный размер submission файла')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e47da6-cf9d-467e-88ed-bbca855bef28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
